# ğŸ¤– Compagnon IA - Smartimmo

SystÃ¨me d'intelligence artificielle conversationnelle pour l'application Smartimmo, basÃ© sur **Mistral 7B** (local via Ollama) et **RAG** (Retrieval-Augmented Generation) avec Qdrant.

---

## ğŸ¯ Objectif

Fournir une assistance contextuelle aux utilisateurs de Smartimmo pour :
- RÃ©pondre aux questions sur la gestion immobiliÃ¨re
- Guider dans l'utilisation de l'application
- Proposer des actions rapides selon le contexte
- AccÃ©lÃ©rer les workflows mÃ©tier

---

## âœ¨ FonctionnalitÃ©s

### **MVP (Version 1.0)** âœ…

- âœ… **Chat conversationnel** avec streaming en temps rÃ©el
- âœ… **RAG (Retrieval-Augmented Generation)** : rÃ©ponses basÃ©es sur la base de connaissances
- âœ… **Base de connaissances** : 4 guides (~48 chunks indexÃ©s)
- âœ… **Actions contextuelles** : 3 actions max selon la page (baux, transactions, dashboard)
- âœ… **Interface intuitive** : bouton flottant + panneau latÃ©ral (Drawer)
- âœ… **SÃ©curitÃ©** : rate-limiting (60 req/min), timeout (30s), validation des inputs
- âœ… **100% local** : pas de cloud, donnÃ©es privÃ©es

### **Roadmap (Post-MVP)**

- [ ] Historique des conversations
- [ ] DÃ©tection automatique du contexte (entitÃ© sÃ©lectionnÃ©e, filtres actifs)
- [ ] Suggestions intelligentes de questions
- [ ] Input vocal + synthÃ¨se vocale
- [ ] Multi-langue (FR, EN)
- [ ] Analytics (questions frÃ©quentes, amÃ©lioration KB)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (UI)                          â”‚
â”‚  - Bouton flottant (React + Framer)    â”‚
â”‚  - Drawer shadcn/ui (panneau latÃ©ral)  â”‚
â”‚  - Chat (streaming SSE)                 â”‚
â”‚  - Actions contextuelles (3 max)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“ HTTP/SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend (Next.js API Routes)           â”‚
â”‚  - /api/ai/search (recherche RAG)       â”‚
â”‚  - /api/ai/chat (chat streaming)        â”‚
â”‚  - Guards (rate-limit, timeout, input)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG System      â”‚  LLM (Mistral 7B)    â”‚
â”‚  - Qdrant        â”‚  - Ollama (local)    â”‚
â”‚  - Embeddings    â”‚  - Streaming SSE     â”‚
â”‚  - Top-K (5)     â”‚  - Max 1024 tokens   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Base de Connaissances (KB)             â”‚
â”‚  - docs/kb/*.md (4 documents)           â”‚
â”‚  - Chunking (800 chars, overlap 200)    â”‚
â”‚  - Embeddings bge-small-en (384 dim)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

Voir [QUICK_START.md](QUICK_START.md) pour le dÃ©marrage rapide (5 minutes).

### **RÃ©sumÃ© ultra-rapide**

```bash
# 1. Services
docker-compose up -d
ollama serve && ollama pull mistral

# 2. Variables ENV (.env.local)
# (Voir SETUP_ENV.md)

# 3. Ingestion
npm run ingest:kb

# 4. Lancer
npm run dev
```

---

## ğŸ“š Base de connaissances

### **Documents actuels** (docs/kb/)

| Fichier | Sujet | Lignes | Chunks |
|---------|-------|--------|--------|
| `guide_baux.md` | Baux, IRL, quittances | 340 | ~12 |
| `guide_transactions.md` | Transactions, rapprochement | 280 | ~10 |
| `glossaire_fiscal.md` | DÃ©finitions fiscales | 220 | ~15 |
| `onboarding.md` | Guide de dÃ©marrage | 320 | ~11 |

**Total** : ~1,160 lignes, ~48 chunks indexÃ©s dans Qdrant.

### **Ajouter de nouveaux documents**

1. CrÃ©er un fichier `.md` dans `docs/kb/`
2. Structurer avec des headings (`##`, `###`)
3. Lancer `npm run ingest:kb`

Voir [docs/USAGE.md](docs/USAGE.md) pour les bonnes pratiques de rÃ©daction.

---

## ğŸ”§ Configuration

### **Variables d'environnement (.env.local)**

```bash
# Qdrant (Vector Database)
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION=smartimmo_kb

# Embeddings
EMBEDDING_MODEL=bge-small-en
EMBEDDING_DIMENSION=384

# Mistral via Ollama
MISTRAL_BASE_URL=http://localhost:11434
MISTRAL_MODEL=mistral

# Limites
AI_MAX_TOKENS=1024
AI_TIMEOUT_MS=30000
AI_RATE_LIMIT_RPM=60
```

Voir [SETUP_ENV.md](SETUP_ENV.md) pour la configuration complÃ¨te.

---

## ğŸ§ª Tests

### **Validation complÃ¨te**

Voir [AI_VALIDATION_TESTS.md](AI_VALIDATION_TESTS.md) pour tous les tests.

### **Tests rapides**

```bash
# API search
curl -X POST http://localhost:3000/api/ai/search \
  -H "Content-Type: application/json" \
  -d '{"query":"loyer","topK":3}'

# API chat
curl -X POST http://localhost:3000/api/ai/chat \
  -H "Content-Type: application/json" -N \
  -d '{"query":"Qu'\''est-ce que l'\''IRL ?"}'

# UI
# 1. Ouvrir http://localhost:3000
# 2. Cliquer sur le bouton flottant (bottom-right)
# 3. Poser : "Qu'est-ce que l'IRL ?"
```

---

## ğŸ“Š MÃ©triques

### **Performance**

| MÃ©trique | Valeur | Cible |
|----------|--------|-------|
| Temps de rÃ©ponse (search) | ~200ms | < 500ms |
| Temps de rÃ©ponse (chat) | ~3s | < 5s |
| Latence premiÃ¨re chunk | ~500ms | < 1s |
| Chunks par recherche | 5 | 3-10 |
| Score min pertinence | 0.7 | > 0.6 |

### **CapacitÃ©**

| MÃ©trique | Valeur actuelle | Limite |
|----------|-----------------|--------|
| Documents KB | 4 | IllimitÃ© |
| Chunks totaux | ~48 | > 10k |
| Tokens max/rÃ©ponse | 1024 | Configurable |
| RequÃªtes/min | 60 | Configurable |

---

## ğŸ”’ SÃ©curitÃ©

### **ImplÃ©mentÃ©**

- âœ… **Rate limiting** : 60 requÃªtes/minute par IP
- âœ… **Timeout** : 30 secondes max par requÃªte
- âœ… **Validation inputs** : longueur max, strip HTML
- âœ… **DÃ©tection PII** : emails, tÃ©lÃ©phones (logs only)
- âœ… **Variables ENV** : `.env.local` ignorÃ© par git

### **Recommandations Production**

- [ ] Authentification utilisateur (rate limit par user, pas IP)
- [ ] HTTPS obligatoire (TLS 1.3)
- [ ] Monitoring (Sentry, Datadog)
- [ ] Logs anonymisÃ©s (pas de PII)
- [ ] Backup Qdrant (vector DB)
- [ ] WAF (Web Application Firewall)

---

## ğŸ› ï¸ Stack technique

| Composant | Technologie | Version |
|-----------|-------------|---------|
| **LLM** | Mistral 7B | Latest |
| **Embeddings** | bge-small-en-v1.5 | 384 dim |
| **Vector DB** | Qdrant | Latest |
| **Orchestration** | Ollama | Latest |
| **Framework** | Next.js | 14.2+ |
| **UI** | shadcn/ui + Tailwind | - |
| **Animations** | Framer Motion | 12.23+ |
| **Client IA** | Transformers.js | 2.17+ |

---

## ğŸ“– Documentation

| Fichier | Description |
|---------|-------------|
| [QUICK_START.md](QUICK_START.md) | DÃ©marrage rapide (5 min) |
| [SETUP_ENV.md](SETUP_ENV.md) | Configuration variables ENV |
| [AI_VALIDATION_TESTS.md](AI_VALIDATION_TESTS.md) | Tests de validation |
| [docs/USAGE.md](docs/USAGE.md) | Guide rÃ©daction KB |
| [src/app/api/ai/README.md](src/app/api/ai/README.md) | Doc API endpoints |
| [AI_IMPLEMENTATION_COMPLETE.md](AI_IMPLEMENTATION_COMPLETE.md) | RÃ©capitulatif complet |

---

## ğŸ¤ Contribution

### **Ajouter du contenu Ã  la KB**

1. CrÃ©er un fichier `.md` dans `docs/kb/`
2. Respecter les [bonnes pratiques](docs/USAGE.md)
3. Lancer `npm run kb:rebuild`

### **AmÃ©liorer les prompts**

Modifier `src/lib/ai/rag/prompt.ts` :
- `buildSystemPrompt()` : identitÃ© de l'assistant
- `formatContext()` : formatage du contexte

### **Ajouter des actions contextuelles**

Modifier `src/ui/companion/CompanionActions.tsx` :
- Fonction `getActionsForRoute(route)` : ajouter vos routes

---

## ğŸ› DÃ©pannage

### **Ollama ne rÃ©pond pas**

```bash
# VÃ©rifier le service
curl http://localhost:11434/api/tags

# RedÃ©marrer
ollama serve
```

### **Qdrant inaccessible**

```bash
# VÃ©rifier Docker
docker ps

# RedÃ©marrer
docker-compose restart qdrant
```

### **Chat ne stream pas**

VÃ©rifier les headers de rÃ©ponse :
- `Content-Type: text/event-stream`
- `Cache-Control: no-cache`
- `Connection: keep-alive`

### **Scores de recherche faibles (<0.5)**

- RÃ©ingÃ©rer la KB : `npm run kb:rebuild`
- VÃ©rifier que les documents contiennent bien le sujet
- Tester avec des mots-clÃ©s exacts

---

## ğŸ“ Support

- **Documentation** : Voir les fichiers `.md` Ã  la racine
- **Issues** : CrÃ©er une issue GitHub
- **Email** : tech@smartimmo.fr (fictif pour exemple)

---

## ğŸ“„ Licence

PropriÃ©taire - Smartimmo Â© 2025

---

## ğŸ‰ Remerciements

- **Mistral AI** pour le modÃ¨le Mistral 7B
- **Ollama** pour l'orchestration locale
- **Qdrant** pour la vector database
- **Hugging Face** pour Transformers.js
- **shadcn/ui** pour les composants React

---

**ğŸš€ DÃ©veloppÃ© avec â¤ï¸ par l'Ã©quipe Smartimmo**

**Version** : 1.0.0 - MVP  
**DerniÃ¨re mise Ã  jour** : 2025-11-03

