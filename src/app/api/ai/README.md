# API IA - Compagnon Smartimmo

Documentation des endpoints IA/RAG pour le compagnon intelligent de Smartimmo.

---

## ğŸ“š Vue d'ensemble

Le systÃ¨me IA repose sur :
- **Mistral 7B** via Ollama (local) pour la gÃ©nÃ©ration de texte
- **Qdrant** (vector database) pour la recherche sÃ©mantique (RAG)
- **Transformers.js** pour les embeddings (bge-small-en ou all-MiniLM-L6-v2)

---

## ğŸ” SÃ©curitÃ©

### Rate Limiting
- **60 requÃªtes/minute** par IP (configurable via `AI_RATE_LIMIT_RPM`)
- Headers de rÃ©ponse :
  - `X-RateLimit-Remaining` : requÃªtes restantes
  - `X-RateLimit-Reset` : date de rÃ©initialisation

### Timeouts
- **30 secondes** max par requÃªte (configurable via `AI_TIMEOUT_MS`)
- Abandon automatique si dÃ©passement

### Validation des inputs
- Longueur max : 500 caractÃ¨res pour les queries
- DÃ©tection PII basique (emails, tÃ©lÃ©phones) pour logs
- Nettoyage HTML/scripts

---

## ğŸ› ï¸ Endpoints

### 1. `/api/ai/search` - Recherche sÃ©mantique

Recherche dans la base de connaissances (RAG).

**MÃ©thode** : `POST` ou `GET`

**Request (POST)** :
```json
{
  "query": "Comment crÃ©er un bail ?",
  "topK": 5,           // Optionnel (dÃ©faut: 5, max: 20)
  "tags": ["baux"]     // Optionnel (filtre par tags)
}
```

**Request (GET)** :
```
GET /api/ai/search?query=Comment+crÃ©er+un+bail&topK=3
```

**Response** :
```json
{
  "chunks": [
    {
      "id": "chunk-1",
      "text": "Pour crÃ©er un bail...",
      "score": 0.92,
      "source": "guide_baux.md",
      "tags": ["baux", "creation"]
    }
  ],
  "query": "Comment crÃ©er un bail ?",
  "count": 5
}
```

**Codes d'erreur** :
- `400` : RequÃªte invalide
- `429` : Rate limit dÃ©passÃ©
- `500` : Erreur serveur

---

### 2. `/api/ai/chat` - Chat conversationnel (streaming)

Chat avec Mistral via Ollama, avec contexte RAG automatique.

**MÃ©thode** : `POST`

**Request** :
```json
{
  "query": "Comment indexer un loyer ?",
  "context": [          // Optionnel (sinon RAG auto)
    {
      "text": "L'IRL est publiÃ© par l'INSEE..."
    }
  ],
  "mode": "normal"      // Optionnel : "normal" | "strict"
}
```

**Modes** :
- `normal` : Assistant peut extrapoler lÃ©gÃ¨rement
- `strict` : RÃ©pond UNIQUEMENT avec le contexte fourni

**Response (SSE stream)** :

Format Server-Sent Events (text/event-stream) :

```
data: {"type":"chunk","content":"Pour indexer","done":false}

data: {"type":"chunk","content":" un loyer","done":false}

data: {"type":"done","content":"","done":true,"usedChunks":[...]}
```

**Types de messages** :
- `chunk` : Fragment de texte
- `done` : Fin de stream (avec `usedChunks`)
- `error` : Erreur lors de la gÃ©nÃ©ration

**Codes d'erreur** :
- `400` : RequÃªte invalide
- `429` : Rate limit dÃ©passÃ©
- `500` : Erreur serveur

---

## âš™ï¸ Variables d'environnement

### Obligatoires

```bash
# Qdrant
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION=smartimmo_kb

# Mistral via Ollama
MISTRAL_BASE_URL=http://localhost:11434
MISTRAL_MODEL=mistral
```

### Optionnelles

```bash
# Embeddings
EMBEDDING_MODEL=Xenova/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# SÃ©curitÃ© & limites
AI_MAX_TOKENS=1024
AI_TIMEOUT_MS=30000
AI_RATE_LIMIT_RPM=60

# Redis (pour rate-limiting distribuÃ©)
REDIS_URL=redis://localhost:6379
```

---

## ğŸ“Š MÃ©triques & Logs

Les endpoints loggent automatiquement :
- Nombre de chunks rÃ©cupÃ©rÃ©s (scores)
- Temps de rÃ©ponse
- Erreurs Ã©ventuelles
- PII dÃ©tectÃ©e (warning)

**Format des logs** :
```
[RAG] RÃ©cupÃ©ration du contexte pour: "Comment crÃ©er..."
[RAG] 5 chunks rÃ©cupÃ©rÃ©s (scores: 0.920, 0.875, 0.832, 0.801, 0.765)
```

---

## ğŸ§ª Tests

### Healthcheck Ollama

```bash
curl http://localhost:11434/api/tags
```

### Healthcheck Qdrant

```bash
curl http://localhost:6333/collections
```

### Test /api/ai/search

```bash
curl -X POST http://localhost:3000/api/ai/search \
  -H "Content-Type: application/json" \
  -d '{"query":"bail","topK":3}'
```

### Test /api/ai/chat (streaming)

```bash
curl -X POST http://localhost:3000/api/ai/chat \
  -H "Content-Type: application/json" \
  -N \
  -d '{"query":"Qu'\''est-ce qu'\''un bail ?"}'
```

---

## ğŸš¨ DÃ©pannage

### Erreur "Ollama API error: 404"
â†’ VÃ©rifier que Ollama est lancÃ© et que le modÃ¨le `mistral` est installÃ© :
```bash
ollama pull mistral
ollama serve
```

### Erreur "Qdrant connection failed"
â†’ VÃ©rifier que Qdrant est lancÃ© (Docker) :
```bash
docker-compose up -d qdrant
```

### Pas de rÃ©sultats de recherche
â†’ La base de connaissances est vide. Lancer l'ingestion :
```bash
npm run ingest:kb
```

### Timeout lors du chat
â†’ Augmenter `AI_TIMEOUT_MS` dans `.env` (ex: 60000 pour 60s)

---

## ğŸ“– Architecture

```
Client (UI)
    â†“
/api/ai/chat
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Guards                             â”‚
â”‚  - Rate Limit (60 req/min)         â”‚
â”‚  - Safe Input (sanitize, PII)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG Retrieve                       â”‚
â”‚  - Query â†’ Embedding (Transformers) â”‚
â”‚  - Search Qdrant (top-5)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prompt Builder                     â”‚
â”‚  - System (identitÃ© IA)             â”‚
â”‚  - Context (chunks RAG)             â”‚
â”‚  - User (question)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mistral Client (Ollama)            â”‚
â”‚  - Stream generation                â”‚
â”‚  - Timeout (30s)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
SSE Stream â†’ Client
```

---

## ğŸ”— Liens utiles

- [Ollama Docs](https://ollama.ai/docs)
- [Qdrant Docs](https://qdrant.tech/documentation/)
- [Transformers.js](https://huggingface.co/docs/transformers.js)

---

**Version** : PR #1 - MVP
**DerniÃ¨re mise Ã  jour** : 2025-11-03

